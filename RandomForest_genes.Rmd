---
title: "T Cell Signaling Analysis"
author: "Matthew Wither"
date: "1/31/22"
output: html_document
editor_options: 
  chunk_output_type: console
---
  
Load packages and user-defined functions
```{r Load packages, eval=FALSE}
library(DescTools)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(RColorBrewer)
suppressPackageStartupMessages(library(ComplexHeatmap))
library(viridis)
library(circlize)
library(randomForest)
library(caret)
library(pbmcapply)
library(pbapply)
library(patchwork)
library(VennDiagram)

compute_percentage <- function(x) {x/sum(x) * 100}

make_kfold_splits <- function(df, kfolds = 5, ntimes = 5) {
  
  #Folds are the number of equal-sized partitions of the dataframe after stratification,
  #preserving relative frequencies of each condition per fold.
  
  #Times is how many times to independently repeat the k-fold splitting
  
  splits <- caret::createMultiFolds(df$Cond, k = kfolds, times = ntimes)
  splits
  
}

do_RF <- function(ksplit, df, class_name = "Cond", predictor_vars, mtry = NA, tune_mtry = FALSE, downsample = T) {
  
  #Split data
  training_data <- df[ksplit,]
  test_data <- df[-ksplit,]
  
  #Train model
  if (is.na(mtry)) {
    
    if(tune_mtry) {
      #Optimize mtry on error rate
      rf <- tuneRF(training_data[,predictor_vars], training_data[,class_name],
                   stepFactor = 0.6,
                   plot = FALSE,
                   ntreeTry = 150,
                   trace = TRUE,
                   improve = 0.05,
                   doBest = TRUE)
    } else {
      
      #Write formula
      rf_formula <- as.formula(paste(paste0(class_name, " ~"), paste(predictor_vars, collapse = " + ")))
      #Use default mtry value
      rf <- randomForest(rf_formula, data = training_data, proximity = TRUE, na.action = na.roughfix)
    
    }
    
    
  } else {
    
    #Use specified mtry value
    rf_formula <- as.formula(paste(paste0(class_name, " ~"), paste(predictor_vars, collapse = " + ")))
    rf <- randomForest(rf_formula, data = training_data, mtry = mtry, proximity = TRUE, na.action = na.roughfix)
    
    }
  
  #Validate model
  #Downsample validation data for balanced test data
  if (downsample) {
    test_data <- caret::downSample(test_data[, colnames(test_data)[!(colnames(test_data) == "Cond")] ], test_data$Cond, yname = "Cond")
  }
  
  p1 <- predict(rf, test_data)
  p1_output <- confusionMatrix(p1, test_data[,class_name], mode = "everything")
  p1_output
  
}

get_confusion_matrix <- function(result, apply_dim) {
  conf_mat <- result$table
  CM <- matrix(conf_mat, ncol = ncol(conf_mat), dimnames = dimnames(conf_mat))
  
  if (apply_dim == 1) {
    CM <- matrix(apply(CM, apply_dim, compute_percentage), ncol = ncol(conf_mat), nrow = ncol(conf_mat), dimnames = dimnames(CM), byrow = T)
  } else if (apply_dim == 2) {
    CM <- matrix(apply(CM, apply_dim, compute_percentage), ncol = ncol(conf_mat), nrow = ncol(conf_mat), dimnames = dimnames(CM), byrow = F)
  }
  
  CM
}

get_model_performance <- function(result) {
  as.matrix(result$byClass)
}

get_model_stats <- function(result) {
  result$overall
}

summarize_kfold_model <- function(model_results, apply_dim) {
  
  summary <- list()
  
  l <- length(model_results)
  
  #Average all confusion matrices
  CM_list <- lapply(model_results, FUN = get_confusion_matrix, apply_dim = apply_dim)
  CM_mean <- Reduce("+", CM_list)/l
  summary[["CM"]] <- CM_mean
  
  #mean +/- SD for performance metrics
  metrics_list <- lapply(model_results, FUN = get_model_performance)
  
  metrics_mean <- as.data.frame(Reduce("+", metrics_list)/l)
  metrics_sd <- apply(array(unlist(metrics_list), c(dim(metrics_mean), l)), c(1,2), sd)
  
  metrics_mean$Cond <- factor(gsub("Class: ", '', rownames(metrics_mean)), levels = rownames(CM_mean))
  metrics_mean <- pivot_longer(metrics_mean, cols = -(length(colnames(metrics_mean))), names_to = "metric", values_to = "score")
  
  metrics_sd <- as.data.frame(metrics_sd)
  colnames(metrics_sd) <- metrics_mean$metric[1:11]
  metrics_sd$Cond <- levels(metrics_mean$Cond)
  metrics_sd <- pivot_longer(metrics_sd, cols = 1:11, names_to = "metric", values_to = "SD")
  
  summary[["metrics"]] <- as.data.frame(metrics_mean)
  summary[["metrics_sd"]] <- as.data.frame(metrics_sd)
  
  #overall statistics
  overall_stats <- lapply(model_results, FUN = get_model_stats)
  overall_mean <- Reduce("+", overall_stats)/l
  summary[["overall"]] <- overall_mean
  
  summary
  
}

#Uses red,white,blue color map
make_CM_heatmap <- function(mod, breaks = c(0,40,80)) {
  labels_rows <- rowAnnotation(Cond = factor(rownames(mod$CM), levels = rownames(mod$CM)),
                               col = list(Cond = pMHC_colors),
                               simple_anno_size = unit(2, "mm"),
                               show_annotation_name = FALSE, show_legend = F)
  
  labels_columns <- HeatmapAnnotation(Cond = factor(rownames(mod$CM), levels = rownames(mod$CM)),
                                      col = list(Cond = pMHC_colors),
                                      simple_anno_size = unit(2, "mm"),
                                      show_annotation_name = FALSE, show_legend = F)
  
  CM_palette <- colorRamp2(breaks, c("blue", "white", "red"))
  
  hm <- Heatmap(mod$CM, cluster_rows = F, cluster_columns = F,
                col <- CM_palette,
                cell_fun = function(j, i, x, y, width, height, fill) {
                  grid.text(paste0(round(mod$CM[i, j],1), "%"), x, y, gp = gpar(fontsize = 10, fontface = "bold"))},
                name = "Pred. %",
                row_title = "Predicted",
                right_annotation = labels_rows,
                bottom_annotation = labels_columns,
                show_row_names = F, show_column_names = F,
                column_title = "True")

  return(hm)
  
}

get_stat_byClass <- function(m, name, stat = "F1") {
  out.df <- subset(m$metrics, metric == stat)
  sd <- subset(m$metrics_sd, metric == stat)
  out.df$SD <- sd$SD
  out.df$model <- as.character(name)
  as.data.frame(out.df)
}

gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

```

----------------------------------------------------------------

Load saved cds files and gene lists
```{r}

main_dir <- "/Users/matthewjwither/Desktop/analysis_objects/"
setwd(main_dir)

#Erk/NFAT targets
cds <- readRDS("cds3.rds")

#Full scRNAseq gene list
cds2 <- readRDS("cds_full.rds")

aff_all <- readRDS("aff_fits_fullgenelist.rds")
dose_all <- readRDS("dose_fits_fullgenelist.rds")

aff_EN <- readRDS("aff_fits_ErkNFAT.rds")
dose_EN <- readRDS("dose_fits_ErkNFAT.rds")

regulons_final <- readRDS("regulons_final.rds")

gene_fits <- readRDS("gene_fits.rds")


#Provide a named vector of colors to be used for bar plots
pMHC_colors <-c("02pmolA" = "plum1", "2pmolA" = "mediumorchid2", "20pmolA" = "darkorchid3", "20pmolPA" = "#E38E14", "80pmolPA" = "#A17339")

theme_set(theme_bw())

```

----------------------------------------------------------------

Machine learning - Random Forest

00. Get Scaled expression matrix
```{r}

cond_subset <- c("20pmolA", "02pmolA", "20pmolPA")

pData <- as.data.frame(colData(cds2))
cell_subset <- subset(pData, Cond %in% cond_subset)
cells <- cell_subset$barcode

expressiondata <- as.matrix(normalized_counts(cds2))

rData <- as.data.frame(rowData(cds2))

sc_barcodes <- colnames(expressiondata)
ENS_names <- rownames(expressiondata)

#Swap target id for gene short name
gene_row_names <- match(ENS_names, rData$id)
rownames(expressiondata) <- rData$gene_short_name[gene_row_names]

expr_mat <- t(expressiondata)
scaled_mat <- scale(expr_mat)
scaled_mat <- scaled_mat[cells,]

```

0. Get predictor gene lists
```{r}

#subset and append columns for each set of gene predictors
#Find gene lists for each RF model

#Use top genes for dose or affinity effect combined
top <- bind_rows(aff_all, dose_all)
top$abs <- abs(top$normalized_effect)
top <- top[order(-top$abs),]

good_genes <- top$gene_short_name[!endsWith(top$gene_short_name, "Rik")]
top <- subset(top, gene_short_name %in% good_genes)

top_genes <- top$gene_short_name[1:200]
top_genes <- unique(top_genes)[1:154]

#Replace hyphens with underscores for the random forest syntax
top_genes <- gsub("-", "_", top_genes)

module_genes <- subset(regulons_final, !is.na(regulon))
module_genes <- rownames(module_genes)

#The 1,089 Erk/NFAT tartgets identified in bulk RNAseq experiment
EN_genes <- names(gene_fits)


#If we compare the performance (i.e accuracy and precision) of the full vs module gene models, we can get a sense for the relative contribution to ligand discrimination
# of the top NFAT/Erk regulated genes vs all genes, which likely include targets of other TFs (i.e NF-kb).

#Let's compare the full gene list with the genes contained in the 8 modules. How many are overlapping, which ones are unique to the full list and indicate decoding by other TFs?
#Normalize the number of predictor genes for each model. Good to try starting with the number of module genes and take this number of genes from the full DEG list.


#Venn diagram of the two gene lists
grid.draw(venn.diagram(x = list(top_genes,EN_genes),
                     category.names = c("All", "Erk/NFAT"),
                     filename = NULL,
                     cex = 1,
                     cat.cex = 1,
                     lwd = 2))

grid.draw(venn.diagram(x = list(top_genes,module_genes),
                     category.names = c("All", "Module"),
                     filename = NULL,
                     cex = 1,
                     cat.cex = 1,
                     lwd = 2))




```

1. K-fold cross validation
```{r}

all_DEGs <- unique(c(aff_all$gene_short_name, dose_all$gene_short_name))
all_DEGs <- unique(c(all_DEGs, module_genes))
data <- as.data.frame(scaled_mat[,all_DEGs])

#Replace hyphens with underscores for the random forest syntax
colnames(data) <- gsub("-", "_", colnames(data))

data$Cond <- cell_subset$Cond
data$Cond <- factor(data$Cond, levels = cond_subset)


splits <- make_kfold_splits(df = data, ntimes = 5)

```

2. Train and validate model - gene expression
```{r}

models <- list()

models[["Full"]] <- pblapply(splits, FUN = do_RF, df = data, predictor_vars = top_genes, downsample = T)
models[["Modules"]] <- pblapply(splits, FUN = do_RF, df = data, predictor_vars = module_genes, downsample = T)


```

3. Summarize model performance
```{r}

#compute percentage over:
#rows(precision) - apply_dim = 1
#columns(sensitivity) - apply_dim = 2

metrics <- lapply(models, summarize_kfold_model, apply_dim = 1)

```

4. Plot confusion matrix
```{r}
#Single heatmap per model - red/white/blue color map
hm_list <- lapply(metrics, make_CM_heatmap)

setwd("/Users/matthewjwither/Desktop")
pdf(file = "model_genes_CMs_Supp.pdf", width = 5.5, height = 3)
draw(hm_list[["Modules"]] + hm_list[["Full"]])
dev.off()


```

